{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20bab8d3-fb10-4cf8-87bb-5cd9e16ce829",
   "metadata": {},
   "source": [
    "# Aula 11 - Mínimos Quadrados\n",
    "\n",
    "O objetivo de mínimos quadrados é obter os melhores parâmetros de uma específica função de forma que a curva mais se aproxime dos dados.\n",
    "\n",
    "Supomos um conjunto de dados ($x_i$, $y_i$) que queremos ajustar por uma função linear qualquer $f(x)$\n",
    "\n",
    "Definimos como erro do experimento $i$, $e_i$, a diferença entre o valor determinado pelo experimento $y_i$ e pelo valor aplicado na função $f(x_i)$\n",
    "\n",
    "\\begin{equation}\n",
    "e_i = f(x_i) - y_i \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "Ao escolher o melhor conjunto de parâmetros, queremos que o erro total seja o menor possível. Para isso precisamos minimizar o erro total. Infelizmente, a simples soma dos erros não fornece a melhor função para ser minimizada, pois ela gera um conjunto grande de possíveis soluções. O módulo do erro também não é uma função boa para ser ajustada porque não é uma função contínua. Portanto, a função a ser minimizada será a soma dos quadrados dos erros:\n",
    "\n",
    "\\begin{equation}\n",
    "E = \\sum_i e_i^2 \\tag{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff2dc4-ea60-4d46-aa3e-9a9e708a84a5",
   "metadata": {},
   "source": [
    "## Exemplo de ajuste por uma linha\n",
    "\n",
    "Vamos supor que a função a ser ajustada seja uma função de primeiro grau. Logo, os parâmetros a serem determinados são os parãmetros $a_1$ e $a_2$.\n",
    "\n",
    "$$f(x) = a + bx$$\n",
    "\n",
    "Para obter os valores mínimos derivamos a equação (2) em relação aos parâmetros de ajuste $a_1$ e $a_2$.\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial a} = 0 \\tag{3}$$\n",
    "$$\\frac{\\partial E}{\\partial b} = 0 \\tag{4}$$\n",
    "\n",
    "Vamos primeiramente realizar a derivada da equação (3)\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial a} = \\sum_{i}\\frac{\\partial (e_i^2)}{\\partial a} = \\sum_{i}2e_i\\frac{\\partial e_i}{\\partial a} = \\sum_{i}2e_i\\frac{\\partial f(x_i)}{\\partial a} = \\sum_{i}2e_i = \\sum_{i}2[f(x_i) - y_i] = \\sum_{i}2(a + bx_i - y_i) \\tag{5}$$\n",
    "\n",
    "Em seguida derivamos a equação (4)\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial b} = \\sum_{i}\\frac{\\partial (e_i^2)}{\\partial b} = \\sum_{i}2e_i\\frac{\\partial e_i}{\\partial b} = \\sum_{i}2e_i\\frac{\\partial f(x_i)}{\\partial b} = \\sum_{i}2e_ix_i = \\sum_{i}2[f(x_i) - y_i]x_i = \\sum_{i}2(ax_i + bx_i^2 - y_ix_i) \\tag{6}$$\n",
    "\n",
    "Agora igualamos as derivadas obtidas nas equações (5) e (6) por zero, como mostrado nas equações (3) e (4)\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{matrix}\n",
    "\\sum_{i}2(a + bx_i - y_i) = 0\\\\\n",
    "\\sum_{i}2(ax_i + bx_i^2 - y_ix_i) = 0\n",
    "\\end{matrix}\n",
    "\\end{equation}\n",
    "\n",
    "que simplificamos para:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{matrix}\n",
    "a\\sum_{i}1 + b\\sum_{i}x_i = \\sum_{i}y_i\\\\\n",
    "a\\sum_{i}x_i + b\\sum_{i}x_i^2 = \\sum_{i}y_ix_i\n",
    "\\end{matrix} \\tag{7}\n",
    "\\end{equation}\n",
    "\n",
    "Para simplificar a notação, vamos substituir os somatórios por:\n",
    "\n",
    "$$S = \\sum_i1$$\n",
    "$$S_x = \\sum_ix_i$$\n",
    "$$S_y = \\sum_iy_i$$\n",
    "$$S_{xx} = \\sum_ix_i^2$$\n",
    "$$S_{xy} = \\sum_ix_iy_i \\tag{8}$$\n",
    "\n",
    "Assim a equação 7 fica:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{matrix}\n",
    "aS + bS_x = S_y\\\\\n",
    "aS_x + bS_{xx} = S_{xy}\n",
    "\\end{matrix} \\tag{9}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07afce7c-22a8-4244-aa95-2a278d9c3b05",
   "metadata": {},
   "source": [
    "## Parâmetros do melhor ajuste\n",
    "\n",
    "Finalmente, para obter os melhores parâmetros basta obter os valores de $a$ e $b$ no sistema de equações lineares dado na equação (9).\n",
    "\n",
    "Para obter $a$ vamos eliminar $b$ multiplicando a primeira equação de (9) por $S_{xx}$ e a segunda equação por $-S_x$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{matrix}\n",
    "aSS_{xx} + bS_xS_{xx} = S_yS_{xx}\\\\\n",
    "-aS_x^2 - bS_{xx}S_x = -S_{xy}S_x\n",
    "\\end{matrix} \\tag{10}\n",
    "\\end{equation}\n",
    "\n",
    "Agora somamos as duas equações de (10) e separamos $a$\n",
    "\n",
    "$$aSS_{xx} - aS_x^2 = S_yS_{xx} - S_{xy}S_x$$\n",
    "$$a = \\frac{S_yS_{xx} - S_{xy}S_x}{SS_{xx} - S_x^2} \\tag{11}$$\n",
    "\n",
    "Fazendo procedimento semelhante obtemos o valor de $b$:\n",
    "\n",
    "$$b = \\frac{SS_{xy} - S_xS_y}{SS_{xx} - S_x^2} \\tag{12}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd096fd0-6ac6-44d4-951d-6afb93c6b74e",
   "metadata": {},
   "source": [
    "## Considerando a incerteza dos parâmetros\n",
    "\n",
    "As medidas de um experimento possuem incertezas. Quando fazemos um ajuste, queremos que a curva passe mais próxima dos pontos com menor incerteza. Para considerar esta incerteza defnimos o chamado chi-quadrado $\\chi^2$, que nada mais é do que a equação (2) onde cada erro ao quadrado é dividido pela incerteza ao quadrado.\n",
    "\n",
    "$$\\chi^2 = \\sum_i\\frac{e_i^2}{\\sigma_i^2} \\tag{13}$$\n",
    "\n",
    "Ao derivarmos a equação (13) pelos parâmetros como feito acima, obtemos o mesmo resultado, porém a equação (8) vira:\n",
    "\n",
    "$$S = \\sum_i\\frac{1}{\\sigma^2}$$\n",
    "$$S_x = \\sum_i\\frac{x_i}{\\sigma_i^2}$$\n",
    "$$S_y = \\sum_i\\frac{y_i}{\\sigma_i^2}$$\n",
    "$$S_{xx} = \\sum_i\\frac{x_i^2}{\\sigma_i^2}$$\n",
    "$$S_{xy} = \\sum_i\\frac{x_iy_i}{\\sigma_i^2} \\tag{14}$$\n",
    "\n",
    "E o resultado final é a mesma equação:\n",
    "\n",
    "$$a = \\frac{S_yS_{xx} - S_{xy}S_x}{SS_{xx} - S_x^2}$$\n",
    "\n",
    "$$b = \\frac{SS_{xy} - S_xS_y}{SS_{xx} - S_x^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4193835-43fa-4d06-a379-c263ec366de1",
   "metadata": {},
   "source": [
    "## Obtendo as incertezas dos parâmetros ajustados\n",
    "\n",
    "Para terminar, sabemos que as medidas possuem incertezas associadas aos experimentos e queremos saber como essas incertezas podem ser propagadas para os parâmetros ajustados. Infelizmente, é extremamente complicado considerar as barras de erro nas duas variáveis, não existindo uma solução pré-determinada. Porém, se considerarmos a incerteza apenas na variável dependente, o procedimento se torna mais simples.\n",
    "\n",
    "Devemos lembrar que a equação de propagação de erro é:\n",
    "\n",
    "$$\\sigma_f^2 = \\left(\\frac{\\partial f}{\\partial a_1} \\right)^2\\sigma_{a_1}^2 + \\left(\\frac{\\partial f}{\\partial a_2} \\right)^2\\sigma_{a_2}^2 + \\cdot\\cdot\\cdot + \\left(\\frac{\\partial f}{\\partial a_n} \\right)^2\\sigma_{a_n}^2 = \\sum_i\\left(\\frac{\\partial f}{\\partial a_i} \\right)^2\\sigma_{a_i}^2$$\n",
    "\n",
    "Aplicando essa equação para $a$ e para $b$ supondo que os erros ocorrem apenas em $y$, temos que:\n",
    "\n",
    "$$\\sigma_a^2 = \\sum_i\\left(\\frac{\\partial a}{\\partial y_i} \\right)^2\\sigma_i^2 \\tag{15}$$\n",
    "$$\\sigma_b^2 = \\sum_i\\left(\\frac{\\partial b}{\\partial y_i} \\right)^2\\sigma_i^2 \\tag{16}$$\n",
    "\n",
    "Primeiramente, vamos obter a derivada de $a$ em relação a $y_i$:\n",
    "\n",
    "$$\\frac{\\partial a}{\\partial y_i} = \\frac{\\partial}{\\partial y_i}\\left(\\frac{S_yS_{xx} - S_{xy}S_x}{SS_{xx} - S_x^2} \\right)$$\n",
    "$$\\frac{\\partial a}{\\partial y_i} = \\frac{1}{SS_{xx} - S_x^2}\\frac{\\partial}{\\partial y_i}\\left(S_yS_{xx} - S_{xy}S_x\\right)$$\n",
    "$$\\frac{\\partial a}{\\partial y_i} = \\frac{1}{SS_{xx} - S_x^2}\\left(S_{xx}\\frac{\\partial S_y}{\\partial y_i} - S_x\\frac{\\partial S_{xy}}{\\partial y_i}\\right) \\tag{17}$$\n",
    "\n",
    "Substituindo na equação (17) os valores de $S_y$ e $S_xy$ dados na equação (14) obtemos o resultado da derivada\n",
    "\n",
    "$$\\frac{\\partial a}{\\partial y_i} = \\frac{1}{SS_{xx} - S_x^2}\\left(\\frac{S_{xx}}{\\sigma_i^2} - \\frac{S_xx_i}{\\sigma_i^2}\\right)$$\n",
    "$$\\frac{\\partial a}{\\partial y_i} = \\frac{1}{\\sigma_i^2}\\left(\\frac{S_{xx} - S_xx_i}{SS_{xx} - S_x^2}\\right) \\tag{18}$$\n",
    "\n",
    "Substituindo a equação (18) na equação (15) obtemos:\n",
    "\n",
    "$$\\sigma_a^2 = \\sum_i\\left[\\frac{1}{\\sigma_i^2}\\left(\\frac{S_{xx} - S_xx_i}{SS_{xx} - S_x^2}\\right) \\right]^2\\sigma_i^2$$\n",
    "$$\\sigma_a^2 = \\sum_i\\frac{1}{\\sigma_i^2}\\frac{(S_{xx} - S_xx_i)^2}{(SS_{xx} - S_x^2)^2}$$\n",
    "$$\\sigma_a^2 = \\frac{1}{(SS_{xx} - S_x^2)^2}\\sum_i\\frac{1}{\\sigma_i^2}(S_{xx}^2 - 2S_{xx}S_xx_i + S_x^2x_i^2)$$\n",
    "$$\\sigma_a^2 = \\frac{1}{(SS_{xx} - S_x^2)^2}\\left(S_{xx}^2 \\sum_i\\frac{1}{\\sigma_i^2}- 2S_{xx}S_x\\sum_i\\frac{x_i}{\\sigma_i^2} + S_x^2\\sum_i\\frac{x_i^2}{\\sigma_i^2}\\right)$$\n",
    "$$\\sigma_a^2 = \\frac{1}{(SS_{xx} - S_x^2)^2}\\left(S_{xx}^2 S - 2S_{xx}S_xS_x + S_x^2S_{xx}\\right)$$\n",
    "$$\\sigma_a^2 = \\frac{1}{(SS_{xx} - S_x^2)^2}\\left(S_{xx}^2 S - S_{xx}S_x^2\\right)$$\n",
    "$$\\sigma_a^2 = \\frac{1}{(SS_{xx} - S_x^2)^2}S_{xx}\\left(S_{xx} S - S_x^2\\right)$$\n",
    "$$\\sigma_a^2 = \\frac{S_{xx}}{(SS_{xx} - S_x^2)} \\tag{19}$$\n",
    "\n",
    "Fazendo o mesmo procedimento para (b) temos:\n",
    "\n",
    "$$\\sigma_b^2 = \\frac{S}{(SS_{xx} - S_x^2)} \\tag{20}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d44da7-bbda-4f3a-92b3-a1a044a7df51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
